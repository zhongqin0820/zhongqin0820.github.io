---
title: 翻译：理解深度学习中的卷积操作
date: 2017-12-10 21:18:18
updated: 2017-12-10 21:18:18
categories:
- 机器学习

tags:
- 数学基础
---
# 前言
此文为译文，目的是让自己更好的理解卷积操作。原文地址：[Understanding Convolution in Deep Learning](http://timdettmers.com/2015/03/26/convolution-deep-learning/)

非常fascinating的是作者关于卷积在卷积网络中的应用。之前从来没有想过，为啥卷积网络就卷积了呢？（不过似乎我一直也都是停留在对全连接网络的学习上= =）

<!-- more -->
# 译文
如今，卷积可能是深度学习中最重要的一个概念。卷积操作及卷积网络使深度学习在机器学习任务中表现靠前。但是，什么使得卷积操作如此强大呢？在这篇文章中我会解释卷积操作以及关联它的相关概念帮助你更完全的理解卷积。

虽然已有大量介绍卷积相关的深度学习的博文，但是我发现他们大都因为介绍了过多的不必要的数学细节反而导致令人费解。这篇博文虽然也会介绍一些数学细节，但是我会通过图片的形式展现关键的数学表达式，使其更直观易懂。第一部分是介绍一些通泛的卷积概念以及卷积网络。第二部分则是为深度学习研究人员和专家能够加强理解而准备的一些更高级的概念。

# 什么是卷积？
整篇文章都是建立在去解答这个问题上，因此首先了解大致的方向是很有帮助的。那么，单纯的卷积说的是什么呢？

你可以想象卷积是混淆信息的方式。想象两个装满信息的桶被按照某种指定的规则被倒入一个桶里进行混合。每一个桶里的内容，都有它自己的关于如何混合其他桶中信息的指导方式。因此，卷积是一个按照指定步骤执行的混合信息的操作。

事实上，卷积和其他数学运算一样也可以被数学定义。尽管卷积操作本身十分的复杂，但是对于复杂的等式，它又可以简化表示。因此，为了简化表达，卷积操作被大量用在了物理学以及工程学上。在第二部分，经过一小段数学证明后。我们会关联和整合科学和深度学习的创意，得到更深层次的关于卷积的理解。但是，我们现在先暂时关注卷积在实际中的应用。

# 我们如何对图片做卷积操作？
当我们对图片做卷积时，我们是对两个维度做了卷积（即图片的宽和高方向）。我们混合两个桶中的内容：第一个桶是输入的图片（可以看作是三个像素矩阵组成，因为图像是由RGB三通道组成的；每个像素矩阵中元素的值：0～255）。第二个桶中是卷积核，一个独立的由浮点数组成的矩阵。（可以将它的大小以及模式看作是一个如何混合两个桶中信息的指导方式）。输出的结果在深度学习中被叫做特征图像(feature map)。每个通道都会产生一个特征图像。
![用一个边缘算子与图像做卷积操作的过程](https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/03/convolution.png)

现在，我们演示卷积是如何混合两份信息。一种方法是利用输入图像采样一个小块做卷积操作--我们用100X100的图像，以及3X3的核。因此，我们可以同时采样3X3个像素点（和核做点乘）。最终得到的是一个中心值。当采样完一个地方（3X3）就向一个方向移动一个像素点。循环往复。当所有的像素都被计算后操作才停止。下面的动图展示了卷积操作的一个过程。
![目标图片一个像素点的计算过程](https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/03/aa-convolution-02.gif)
如你所见，为了保证与原图像有同样的密度一致性，这里通常还有一个正则化的过程。

# 为什么作用在图片的卷积操作在机器学习中如此有效？
在一张图像中有大量的我们不需要的冗余信息。一个很好的例子就是`Burda Bootcamp`（这是原文作者一个在快速原型生成的马拉松式的学生实验项目中的项目=  =）在一个项目，作者想要搭建一个用于时尚图片搜索深度自编码器：你上传一张关于时尚单品的照片，自编码器会找出与图中的单品包含的相关风格的图片。

现在，如果你想鉴别不同风格的衣服，衣服的颜色不会有什么帮助，类似的还有衣服的商标等。关键的要素是衣服的形状。通常，女士衬衫的形状是异于短袖，夹克或毛衣的。因此，我们需要过滤图像中不必要的信息。通过卷积操作我们可以很容易完成这个需求。

作者的同事Jannek Thomas用Sobel算子（它的定义与前面的那个那个边缘算子差不多）预处理了数据，得到了重要的边缘信息。这也是为什么卷积操作也叫做滤波。边缘信息的提取对于形状信息的获得非常有帮助。
![上面是提取完边缘信息后的图像](https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/03/autoencoder_fashion_features_and_results.png)

更深入的：很多的核产生很多的特征图像（map）。例如：锐化图像的，模糊图像的。

通过这个过程--输入图像，转化输入，得到转化后的图像将其引入算法中。被成为特征提取工程。特征工程非常困难，拥有的学习资料也非常有限。因此，很少有人能够熟练运用它。有效的特征提取在不同的任务中区别很大。因此，不存在通用的特征。同时，对于时间序列数据，特征几乎收效甚微。识别特征的有效性需要大量的经验。

因此，特征工程非常困难，你必须从零开始一点点去试探。但是，当我们关注图像本身，有什么方法可以自动的找到特征提取的核的吗？

# 引入卷积网络
卷积网络就是干这个的。较于固定我们的核，我们指定一组参数然后让网络训练我们的核。当我们训练我们的卷积网络时，核会随着过程学习，过滤得到更有用的信息。这个过程是全自动的，也被叫做特征学习。特征学习自动得到一个任务的特征。我们所需要做的就是训练我们的网络，去找到一个与新的任务相关的filter。这就是为什么卷积网络如此强大的原因--不再为特征的提取而烦恼。

> 数据编程的概念
> 

通常我们在一个卷积网络中，不会只学习一个核。我们同时学到一个组织（hierarchy）的多个核。例如：一个32X16X16的核应用在一张256X256的图像上会产生32个241X241的特征图像。（这是标准大小，实现的不同大小特跟着改变；image size - kernel size +1）。因此我们自动学习得到的32个新特征拥有与我们的任务相关的所有信息。这些特征又为接下来的核计算提供了输入。一旦我们学习完所有的核，我们就将其传入给一个全连接的网络（简单的网络，用作图像的分类。）。这就是卷积网络所有的应该知道的概念（池化的过程也很重要，但是它的内容也够写一篇博文了）。


# 结束语
放弃了，第二部分还是自己看吧= =翻译的效率实在太低了。