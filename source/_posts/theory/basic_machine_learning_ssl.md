---
title: 机器学习基础概念-半监督学习
date: 2017-11-20 21:35:45
updated: 2017-11-20 21:35:45
categories:
- 机器学习
tags:
- 基础概念
---
# Semi-Supervised Learning
1. 期望最大算法(Expectation Maximum，EM)
2. 高斯混合模型(Gaussian Mixture Model，GMM)
3. 最小割法(Mincut):首次将图论应用于解决SSL问题
4. 调和函数法(Harmonic Function)将预测函数从离散形式扩展到连续形式
5. 流形正则化法(Manifold Regularization)将流形学习的思想用于SSL场景
6. 用于聚类的半监督距离度量学习方法，学习一种距离度量。
7. 将EM和朴素贝叶斯结合，通过引入加权系数动态调整无类标签的样例的影响提高了分类准确度，建立每类中具有多个混合部分的模型，使贝叶斯偏差减小。
8. 协同训练改进算法，不需要充分冗余的视图，而利用两个不同类型的分类器来完成学习
9. 同时解决有类标签样本稀疏和具有附加无类标签样例成对约束的问题

<!-- more -->
# 三个常用基本假设
基于一个事实：未标记样本虽未直接包含标记信息，但若它们与有标记信息样本是从同样的数据源独立同分布采样而来，则它们所包含的关于数据分布的信息对建立模型是有帮助的。

利用好未标记样本来提升模型泛化能力，就是半监督学习研究的重点。

在半监督学习中有三个常用的基本假设来建立预测样例和学习目标之间的关系：
- （1）平滑假设(Smoothness Assumption)：位于稠密数据区域的两个距离很近的样例的类标签相似，也就是说，当两个样例被稠密数据区域中的边连接时，它们在很大的概率下有相同的类标签；相反地，当两个样例被稀疏数据区域分开时，它们的类标签趋于不同。
- （2）聚类假设(Cluster Assumption)：当两个样例位于同一聚类簇时，它们在很大的概率下有相同的类标签。这个假设的等价定义为低密度分离假设(Low Sensity Separation Assumption)，即分类决策边界应该穿过稀疏数据区域，而避免将稠密数据区域的样例分到决策边界两侧。
- （3）流形假设(Manifold Assumption)：将高维数据嵌入到低维流形中，当两个样例位于低维流形中的一个小局部邻域内时，它们具有相似的类标签。

# 四大类学习场景
半监督学习可进一步划分为纯(pure)半监督学习和直推学习（transductive learning）：
- 纯半监督学习假定训练数据中的未标记样本并非待预测数据；
- 而直推学习假定学习过程中所考虑的未标记样本恰是待预测数据，学习的目的就是在未标记样本上获得最优泛化性能。

纯半监督学习是基于开放世界的假设，希望学得的模型能适用于训练过程中未观察到的数据；**而直推学习是基于封闭世界假设，仅试图对学习过程中观察到的未标记数据进行预测。**

从不同的学习场景看，SSL可分为四大类：
## 半监督分类
半监督分类(Semi-Supervised Classification)：是在无类标签的样例的帮助下训练有类标签的样本，获得比只用有类标签的样本训练得到的分类器性能更优的分类器，弥补有类标签的样本不足的缺陷，其中类标签yi取**有限离散值**。

## 半监督回归
半监督回归(Semi-Supervised Regression)：在无输出的输入的帮助下训练有输出的输入，获得比只用有输出的输入训练得到的回归器性能更好的回归器，其中输出yi取**连续值**；

## 半监督聚类
半监督聚类(Semi-Supervised Clustering)：在有类标签的样本的信息帮助下获得比只用无类标签的样例得到的结果更好的簇，提高聚类方法的精度；

## 半监督降维
半监督降维(Semi-Supervised Dimensionality Reduction)：在有类标签的样本的信息帮助下找到高维输入数据的低维结构，同时保持原始高维数据和成对约束(Pair-Wise Constraints)的结构不变，即在高维空间中满足正约束(Must-Link Constraints)的样例在低维空间中相距很近，在高维空间中满足负约束(Cannot-Link Constraints)的样例在低维空间中距离很远。

# 未来的研究方向包括以下一些内容
### 理论分析

### 抗干扰性与可靠性

### 训练样例与参数的选取

### 优化求解
从各种SSL算法的实现过程可以看出，SSL问题大多为非凸、非平滑问题，或整数规划和组合优化问题，存在多个局部最优解，例如求解SSL产生式方法目标函数的EM算法只能得到局部极大值目前主要采用各种放松方法把目标函数近似转化为凸或连续最优化问题，不易得到全局最优解，算法的时空复杂性很高，问题的求解依赖于最优化理论的突破，未来需要研究新的算法求解全局最优解。

### 研究拓展
SSL从产生以来，主要用于实验室中处理人工合成数据，未来的研究一方而需要讨论SSL可以显著提高哪些学习任务的性能，拓展SSL在现实领域的实际应用，另一方而需要制定出一个统一的令人信服的SSL方法的使用规程。此外，目前有许多的半监督分类方法，而对半监督回归问题的研究比较有限。未来有待继续研究半监督分类和半监督回归之间的关系，并提出其他半监督回归方法。

# Active Learning:主动学习
主动学习就是要引入专家知识，通过与外部交互来将部分未标记样本转变为有标记样本。如果不通过外部标记，还可以利用未标记样本，就是半监督学习的研发范围。