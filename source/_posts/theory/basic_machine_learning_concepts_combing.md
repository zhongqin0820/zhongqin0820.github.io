---
title: 机器学习基础概念再梳理
date: 2017-12-28 21:35:45
updated
categories:
- 机器学习
tags:
- 基础概念
---
# 前言
最近真的是被毕设的东西搞疯了。一直以为自己遇到毕设的问题应该是非常容易的。没想到最终却是崩溃了...发现很多知识都不会，或者说根本就不理解。
直到我找到了这篇文章，感觉自己瞬间被打通了任督二脉。不过还是推荐有一点经验的同学自己去看原文[原文地址](http://www.360doc.com/content/13/1020/18/7673502_322833764.shtml)。
接下来的内容只是我摘录的一些原文以及穿插个人的笔记。

<!-- more -->
# 机器学习
何谓学习？
**学习=表示+评价+优化**

| 表示      | 评价             | 优化    |
| ------- | -------------- | ----- |
| 基于实例的方法 | 准确/错误比率        | 组合优化  |
| 近邻方法    | 精确率和召回率        | 贪心搜索  |
| 支持向量机   | 平方误差           | 柱搜索   |
| 超平面方法   | 似然(likelihood) | 分支限界法 |
| 朴素贝叶斯   | 后验概率           | 连续优化  |
| 逻辑斯蒂回归  | 信息增益           | 无约束   |
| 决策树方法   | K-L距离          | 梯度下降  |
| 规则集的方法  | 成本/效用          | 共轭梯度  |
| 命题规则    | 利润             | 拟牛顿法  |
| 逻辑程序    |                | 有约束   |
| 神经网络    |                | 线性规划  |
| 图模型     |                | 二次规划  |
| 贝叶斯网络   |                |       |
| 条件随机场   |                |       |

# 泛化(Generalization)
基本目标是对训练集合中样例的泛化。机器学习初学者最常犯的错误就是在训练数据上做测试，从而产生胜利的错觉。
**交叉验证（Cross Validation）**将训练数据随机地等分为若干份，其中的每一份均可用做测试，而剩下的数据用作训练，然后将每个学习的分类器在它没见过的样例上进行测试，将测试结果取平均后，就可用来评价不同参数设置的性能。

# 过拟合（Overfitting）
当你的分类器在训练数据上准确率为100%，而在测试数据上仅有50%的时候，说明这个分类器发生过拟合。
常见误解是认为其由噪音造成的。
一种理解过拟合的方式是将泛化误差分解为偏置（bias）和方差（variance）。**偏置**度量了学习器倾向于一直学习相同错误的程度。**方差**则度量了学习器倾向于忽略真实信号、学习随机食物的程度。
## 避免过拟合的方法
交叉验证是一种方法。然而最常用的方法是对评价函数增加一个正则项（regularization term）。另外还有卡方测试等统计显著性检测。
## 欠拟合（Underfitting）
为了避免过拟合（方差）时很容易陷入欠拟合（偏置）问题中。

# 维度灾难
"非均匀性的祝福"可以抵消维度灾难。

# 特征工程
现在经常采用的一种方式是先自动产生大量的候选特征，然后根据它们与分类类别的信息增益等方法来选取最好的特征。

# 大数据带来的问题
**可扩展性**
时间和内存的资源有限。
作为一条规则，首先应该在logistics回归之前尝试朴素贝叶斯，在支持向量机之前先尝试近邻。

# 模型集成
最简单的集成技术是bagging。另外还有一个是boosting。

# 结束语
感觉自己对于学习时间的把控是自从十月答应和曹老师做医学影像以来就被浪费算起（感觉自己真的是疯了才会去学一些乱七八糟的：）。接着十一月去了公司实习，然后十二月的时候又执着于自己的一些事情。真的是感觉自己要炸了。留给毕设的时间真的是少的可怜。