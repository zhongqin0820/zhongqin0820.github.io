---
title: 翻译:主动学习调研总结
date: 2018-08-07 15:04:18
categories:
- 机器学习

tags:
- 学习总结
---
# 前言
&emsp;&emsp;此文为译文，原文链接:[Active Learning: Curious AI Algorithms](https://www.datacamp.com/community/tutorials/active-learning)。了解主动学习，一种半监督机器学习算法：从它的定义到它的优势，以及关于它的最新应用与研究。

<!-- more -->
## 前言
&emsp;&emsp;主动学习是你之前一直听说但是因为某些原因从来没有时间去完全了解的课题。今天的博客内容将会解释其背后的理论和它的优势以及它是如何与现如今的机器学习研究相结合的。

&emsp;&emsp;在你缺少标签数据的时候，能够正确使用主动学习技术将会成为一个强有力的助力。主动学习可以看作是一种类似迁移学习的“设计方法”，其同样能够利用少量标签的数据。

~~在下一篇文章中，你将学到更多关于如何使用主动学习结合迁移学习来有效地利用现有（和新）数据。~~

## 动机
&emsp;&emsp;相比一开始就给出关于主动学习的正式定义，我想利用一个简单的例子来使你更好的了解为什么主动学习能够起作用会更有助于你的理解。

![classification](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1518178638/al-eg_pbwzob.png)

&emsp;&emsp;上图摘自([这篇文章](http://burrsettles.com/pub/settles.activelearning.pdf))中，可以看出，最左侧的图中有两个聚类中心，分别是绿色与红色的聚类。精明的读者会知道这是一个分类任务，你希望创建一个“决策边界”（在这种情况下，它只是一条线），将绿色和红色的形状分开。但是，你可以假设你不知道数据点的标签（红色或绿色），并且试图找到每个点的标签的代价是非常昂贵的。因此，你会想要对一小部分的点进行采样并找到那些标签，并使用这些标记的数据点作为分类器的训练数据。

&emsp;&emsp;在中间图中，首先通过随机抽样出一个小子集并对其进行标记，然后利用逻辑回归对训练数据进行分类。然而，你可以看到，使用逻辑回归（蓝色线）创建的决策边界是次优的。这条线明显偏离红色数据点，进入了绿色形状区域。这意味着将会有许多绿色数据点被错误地标记为红色。这种偏离是由于标签的数据点选择不佳造成的。

&emsp;&emsp;在最右边的图片中，再次使用逻辑回归，但是这次，你使用主动学习查询方法选择了一小部分的点。这个新的决策边界是更好的，因为它更好地分离两种颜色。这种改进来自于选择优越的数据点，使得分类器能够创建一个非常好的决策边界。

&emsp;&emsp;主动学习的查询方法是如何选择好点是主动学习主要研究领域之一。接下来，你将看到一些最常用的查询数据点的方法。

## 主动学习：定义和概念
&emsp;&emsp;主动学习中的主要假设是，如果学习算法可以选择它想要学习的数据，它可以比传统方法表现的更好，并且所需的训练数据要少得多。

&emsp;&emsp;但是这些传统的方法到底是什么呢？

&emsp;&emsp;这些任务涉及收集从下层分布中随机抽取的大量数据，并使用这个大数据集来训练能够执行某种预测的模型。你可以把这种典型的方法称为被动学习。

&emsp;&emsp;被动学习中更耗时的任务之一是收集标记数据。在许多设置中，可能存在限制收集大量标记数据的因素。

&emsp;&emsp;让我们以研究胰腺癌为例进行说明。你可能想预测患者是否会患上胰腺癌，然而，你可能只有机会给少数患者进一步检查收集特征等。在这种情况下，相比随机选择患者，我们可以根据特定的标准选择患者。一个典型的标准可能是病人是否饮酒且超过40岁。这个标准不一定是静态的，而是可以根据先前患者的结果而改变。例如，如果你意识到你的模型能够很好地预测超过50岁的人是否得胰腺癌，但要不能很好的预测40-50岁是否得胰腺癌，这可能是你的新衡量标准。

&emsp;&emsp;根据我们收集到的数据**选择**这些患者（或者更一般地，**实例**）**的过程称为主动学习**。

## 场景
&emsp;&emsp;在主动学习中，学习器通常在三种场景或设置下查询实例的标签。在文献中已经考虑的三个主要场景是：

### Membership Query Synthesis(成员查询综合)
&emsp;&emsp;这是一个宽泛的术语，简单的意思是学习器(Learner)生成/构建一个实例（来自一些基础的自然分布）。例如，如果数据是数字的图片，学习者将创建一个与数字类似的图像（它可能被旋转或不被包括的某个数字），并且这个创建的图像被发送给用户(Oracle)来标记。

![merbership query synthesis illustration](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1518178638/membership_wzptzh.png)

### Stream-Based Selective Sampling(基于流的采样)
&emsp;&emsp;在这个设置中，你假设获得一个未标记的实例是十分容易的。基于这个假设，每次选择一个未标记的实例，并允许学习器决定是否想查询实例的标签，或者基于它的信息含量(informativeness)拒绝它。其中，使用查询策略确定实例的信息含量（参见下一节）。按照上面的描述，你将从一组未标记的图像中选择一个图像，确定它是否需要被标记或丢弃，然后重复这个过程。

![stream based selective sampling](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1518178638/stream_kdlsz2.png)

### Pool-Based sampling(基于池的采样)
&emsp;&emsp;与基于流的采样策略一致，此设置假定存在一个拥有大量未标记数据的池。然后根据信息量度量从池中选择实例。**该度量被应用到池中的所有实例**（或者池非常大时，应用在它的一些子集上），**然后在其中选择最翔实(信息量最大)的实例。**这是主动学习研究中最常见的场景。接着使用前两个场景中的例子，所有未标记的数字图像将被排序，然后将选择最佳（最翔实的）实例并请求用户(Oracle)其标签。

![pool based sampling](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1518178638/pool_guqwfe.png)

## Query Strategies(问询策略)
&emsp;&emsp;主动学习器和被动学习器之间的主要或关键区别是，主动学习是基于过去的查询和来自这些查询的响应（标签）来查询实例。如前所述，所有的主动学习场景都需要引入某种关于未标记实例的信息量度量的准则。在这一节中，我将阐释常见课题中三种流行的问询策略方法。由于其使用概率进行衡量，所以也被叫做不确定采样。(希望获得更多关于闻讯策略和更深入的主动学习内容，通常我会推荐你阅读[这个调研文献](http://burrsettles.com/pub/settles.activelearning.pdf))

&emsp;&emsp;我将使用下面的表格来解释问询策略。该表显示了两个数据点（实例）和每个实例具有每个标签的概率。`d1`实例对应标签`A`,`B`,`C`的概率分别是`0.9`,`0.09`,`0.01`，`d2`则对应是`0.2`,`0.5`,`0.3`。

|  实例  | 标签A  | 标签B  | 标签C  |
| :--: | :--: | :--: | :--: |
|  d1  | 0.9  | 0.09 | 0.01 |
|  d2  | 0.2  | 0.5  | 0.3  |

### Least Confidence (LC)
&emsp;&emsp;在这种策略中，学习器选择其最有可能的标签中最不自信的实例。在表中，学习器对`d1`实例所属的标签很有信息，因为它认为它应该被标记为标签`A`的概率为`0.9`。而对于实例`d2`而言，由于它的概率更加分散，并且学习器认为它应该被标记为标签`B`的概率只有`0.5`，所以它不太确定实例`d2`的标签。因此，使用Least Confidence(LC)问询策略时，学习器会问询`d2`实例的标签。

### Margin Sampling
&emsp;&emsp;LC策略的缺点是，它只考虑最有可能的标签并且忽略其他标签的概率。Margin Sampling问询策略则是通过选择在第一和第二最可能标签之间具有最小差异的实例来克服这一缺陷。对于实例`d1`，它的第一和第二最可能标签之间的差异是`0.81`（`0.9-0.09`），而对于`d2`则是`0.2`（`0.5-0.3`）。因此，学习器会再次选择`d2`实例问询它的标签。

### Entropy Sampling
&emsp;&emsp;为了利用所有可能的标签概率，你可以使用一种流行的称为**熵**的度量标准。将[熵公式](https://www.wikiwand.com/en/Entropy_(information_theory))应用于每个实例，并对具有最大熵值的实例进行问询。以我们的例子为例，实例`d1`的熵值为`0.155`而`d2`的熵值为`0.447`，因此，学习器会又选择`d2`实例问询它的标签。

## 小结
&emsp;&emsp;到目前为止，你已经了解了组成主动学习的不同组成部分。把所有的步骤放在一起似乎有点混乱或困难，但在这一节中，你将通过一个完整的例子——尽管这是一个非常简单的例子。

### 第0步：收集数据
&emsp;&emsp;这一步可能看起来微不足道，但是，重要的是要确保所收集的数据集**代表数据的真实分布**。换言之，尽量避免大量偏离的数据。实际上，由于法律、时间或可用性等限制，不可能有一个完全代表性的样本。

&emsp;&emsp;在这个示例中，您将拥有以下`5`个数据点。特征`A`和特征`B`表示数据点可能具有的某些特征。重要的是要注意，我们收集的数据是未标记的。

|  实例  | 特征A  | 特征B  |
| :--: | :--: | :--: |
|  d1  |  10  |  0   |
|  d2  |  4   |  9   |
|  d3  |  8   |  5   |
|  d4  |  3   |  3   |
|  d5  |  5   |  5   |

### 第1步：分割种子点和未标记数据集
&emsp;&emsp;接下来，你需要将收集的数据分割成一个非常小的数据集(`L`abeled)和相对一个大的未标记的数据集(`U`nlabeled)。我们将标记数据集`L`中所包含的实例。在主动学习术语中，我们称这种小标记的数据集`L`为种子。并且，对于使用的未标记数据的设置数量或百分比没有特别要求。一旦你分出种子数据集`L`，你就应该给其包含的实例都打上标签。

**注意**，在大多数文献中，研究人员不使用用户或专家来标记这些实例。通常，他们得到一个被完全标记的数据集，并使用少量的种子（因为它们已经有标签），然后使用剩下的就好像它们未标记一样。每当学习器选择一个实例来问询用户时，他们只需查看实例的标签即可。

&emsp;&emsp;继续说明示例，你选择`d1`和`d3`这两个实例作为种子。在我们的实例中，可能的标签是`“Y”`和`“N”`。

#### 种子/标签训练集

|  实例  | 特征A  | 特征B  |  标签  |
| :--: | :--: | :--: | :--: |
|  d1  |  10  |  0   |  Y   |
|  d3  |  8   |  5   |  N   |

#### 无标签训练集

|  实例  | 特征A  | 特征B  |
| :--: | :--: | :--: |
|  d2  |  4   |  9   |
|  d4  |  3   |  3   |
|  d5  |  5   |  5   |

### 第2步：训练模型
&emsp;&emsp;在分割完我们的数据后，你使用种子来训练我们的学习器，就像一个正常的机器学习项目那样（使用交叉验证等）。此外，所使用的学习器的类型将基于你对领域的知识掌握，因为问询策略中使用了概率，通常使用能够提供实例是否具有特定标签的概率的学习器。

&emsp;&emsp;在这个例子中，你可以使用任何你想要的分类器，在两个标记的实例上进行训练。

### 第3步：选择无标签实例进行标记
&emsp;&emsp;一旦训练好了学习器，就可以选择要问询的一个实例或一些实例。你**必须确定你希望应用的场景类型（即，成员查询综合、基于流的采样或基于池的采样）和问询策略。**

&emsp;&emsp;您将使用**基于池的采样**，其批大小为2。这意味着在每次迭代中，您将从未标记的数据集中选择两个实例，然后将这些实例添加到标记数据集中。您使用`Least Confidence(LC)`来选择实例。你的学习器选择`d2`和`d4`，它们的问询标签分别是`“Y”`和`“N”`。

#### 种子/标签训练集

|  实例  | 特征A  | 特征B  |  标签  |
| :--: | :--: | :--: | :--: |
|  d1  |  10  |  0   |  Y   |
|  d3  |  8   |  5   |  N   |
|  d2  |  4   |  9   |  Y   |
|  d4  |  3   |  3   |  N   |

#### 无标签训练集

|  实例  | 特征A  | 特征B  |
| :--: | :--: | :--: |
|  d5  |  5   |  5   |

### 第4步：停止准则
&emsp;&emsp;现在，你可以重复步骤2和3，直到达到一些停止标准。这意味着，当你有新的标记数据集时，你将重新训练你的学习器，然后选择其他未标记的数据进行查询。一个停止标准可以是查询的实例数量，另一个可以是步骤2和3的迭代次数，也可以在性能没有显著提高到某个阈值以上时停止。

&emsp;&emsp;在这个示例中，你将在一次迭代后停止，因此你的主动学习算法结束了。你也可以有一个单独的测试数据集，你可以评估你的学习器并记录它们的性能。通过这种方式，你可以看到在测试集上的性能是如何通过添加的标记数据得到改善或停滞的。

## 主动学习的应用与近期研究
&emsp;&emsp;自然语言处理（NLP）是主动学习中最热门的领域之一。这是因为在NLP中的许多应用需要大量的标记数据（例如，词性标注，命名实体识别），并且标记这些数据的成本非常高。

&emsp;&emsp;事实上，在NLP中只有少数数据集是自由可用且完全标记的。因此，使用主动学习可以显著减少需要的标记数据的量，并且专家可以更精确地标记它们。同样的推理可以应用于许多语音识别任务，甚至是诸如信息检索之类的任务。

&emsp;&emsp;主动学习仍需大量的研究。许多人已经开始研究使用不同的深度学习算法，如使用CNNs和LSTM作为学习器，结合主动学习框架如何提高他们的效率 ([Kronrod and Anandkumar, 2017](https://arxiv.org/pdf/1707.05928v2); [Sener and Savarese, 2017](https://arxiv.org/abs/1708.00489v2))。在主动学习框架中也进行了与生成性对抗网络（GANS）结合的研究 ([Zhu and Bento, 2017](https://arxiv.org/abs/1702.07956v5))。随着对深度强化学习的兴趣越来越浓厚，有学者正试图将主动学习作为强化学习问题进行重构([Fang et. al, 2017](https://arxiv.org/abs/1708.02383v1))。此外，也有一些尝试通过元学习设置学习主动学习策略的论文([Fang et. al, 2017](https://arxiv.org/abs/1706.08334))。

## 翻译结束语
&emsp;&emsp;重新认识了主动学习，关键是：主动学习框架由5个组件**`(L,U,M,Q,S)`**构成。其中，**`L`**`abled`和**`U`**`nlabeled`分别表示标签训练数据集与无标签训练数据集(L和U之间的关系由采样策略决定)。**`M`**`odel`表示学习器(也常用`Learner`指代)，**`Q`**`uery`表示问询策略，**`S`**`upervisor`表示提供实例对应真实标签的用户(也常用`Oracle`指代)。其中，最关键的环节是**`Q`**：它可以包括**采样测量**（决定样本是如何采样的，即应用场景）和**问询策略**（决定模型应该问询哪个无标签实例的真实标签）。现在，最常用的采样策略是**基于池的采样策略**以及**基于不确定性的问询策略**。