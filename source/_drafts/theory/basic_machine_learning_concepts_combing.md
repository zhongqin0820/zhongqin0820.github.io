---
title: 机器学习基础概念再梳理
date: 2017-12-28 21:35:45
updated: 2017-12-28 21:35:45
categories:
- 机器学习
tags:
- 基础概念
---
# 前言
关于[A Few Useful Things to Know about Machine Learning](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)的笔记摘录。

<!-- more -->
# 机器学习
何谓学习？
**学习=表示+评价+优化**

| 表示      | 评价             | 优化    |
| ------- | -------------- | ----- |
| 基于实例的方法 | 准确/错误比率        | 组合优化  |
| 近邻方法    | 精确率和召回率        | 贪心搜索  |
| 支持向量机   | 平方误差           | 柱搜索   |
| 超平面方法   | 似然(likelihood) | 分支限界法 |
| 朴素贝叶斯   | 后验概率           | 连续优化  |
| 逻辑斯蒂回归  | 信息增益           | 无约束   |
| 决策树方法   | K-L距离          | 梯度下降  |
| 规则集的方法  | 成本/效用          | 共轭梯度  |
| 命题规则    | 利润             | 拟牛顿法  |
| 逻辑程序    |                | 有约束   |
| 神经网络    |                | 线性规划  |
| 图模型     |                | 二次规划  |
| 贝叶斯网络   |                |       |
| 条件随机场   |                |       |

# 泛化(Generalization)
基本目标是对训练集合中样例的泛化。机器学习初学者最常犯的错误就是在训练数据上做测试，从而产生胜利的错觉。
**交叉验证（Cross Validation）**将训练数据随机地等分为若干份，其中的每一份均可用做测试，而剩下的数据用作训练，然后将每个学习的分类器在它没见过的样例上进行测试，将测试结果取平均后，就可用来评价不同参数设置的性能。

# 过拟合（Overfitting）
当你的分类器在训练数据上准确率为100%，而在测试数据上仅有50%的时候，说明这个分类器发生过拟合。
常见误解是认为其由噪音造成的。
一种理解过拟合的方式是将泛化误差分解为偏置（bias）和方差（variance）。**偏置**度量了学习器倾向于一直学习相同错误的程度。**方差**则度量了学习器倾向于忽略真实信号、学习随机食物的程度。

## 避免过拟合的方法
交叉验证是一种方法。然而最常用的方法是对评价函数增加一个正则项（regularization term）。另外还有卡方测试等统计显著性检测。

## 欠拟合（Underfitting）
为了避免过拟合（方差）时很容易陷入欠拟合（偏置）问题中。

# 维度灾难
高纬度的数据存在的问题，一种方法是利用降维算法：如，PCA等。一种是利用特征工程去除冗余特征。

# 特征工程
现在经常采用的一种方式是先自动产生大量的候选特征，然后根据它们与分类类别的信息增益等方法来选取最好的特征。

# 大数据带来的问题
- **可扩展性**
- 时间和内存的资源有限。
- 作为一条规则，首先应该在logistics回归之前尝试朴素贝叶斯，在支持向量机之前先尝试近邻。

# 模型集成
最简单的集成技术是bagging。另外还有一个是boosting。

# 参考资料
- [机器学习那些事](http://www.360doc.com/content/13/1020/18/7673502_322833764.shtml)
